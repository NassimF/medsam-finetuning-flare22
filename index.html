<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>MedSAM on FLARE22: Evaluation and Fine-Tuning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Project page for evaluation and fine-tuning of MedSAM on the MICCAI FLARE22 abdominal CT dataset.">
  <style>
    :root {
      --utsa-orange: #cc5500;
      --utsa-blue: #002244;
      --light-gray: #f5f5f5;
      --dark-text: #222222;
      --muted-text: #555555;
      --link: #004c9b;
      --max-width: 1100px;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      color: var(--dark-text);
      background-color: white;
      line-height: 1.6;
    }

    a {
      color: var(--link);
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    header {
      background: linear-gradient(120deg, var(--utsa-orange), var(--utsa-blue));
      color: white;
      padding: 32px 16px 24px;
    }

    .container {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 0 16px;
    }

    .hero {
      display: flex;
      flex-wrap: wrap;
      align-items: center;
      justify-content: space-between;
      gap: 24px;
    }

    .hero-title {
      flex: 2;
      min-width: 260px;
    }

    .hero-title h1 {
      font-size: 2.4rem;
      margin-bottom: 8px;
    }

    .hero-title p {
      font-size: 1rem;
      color: #f0f0f0;
    }

    .hero-meta {
      flex: 1;
      min-width: 220px;
      text-align: right;
    }

    .hero-meta p {
      font-size: 0.95rem;
    }

    .hero-meta .tag {
      display: inline-block;
      margin-top: 8px;
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.8);
      font-size: 0.8rem;
      text-transform: uppercase;
      letter-spacing: 0.06em;
    }

    nav {
      background-color: rgba(0,0,0,0.07);
      backdrop-filter: blur(4px);
      padding: 8px 0;
    }

    nav ul {
      display: flex;
      flex-wrap: wrap;
      list-style: none;
      gap: 12px;
      font-size: 0.9rem;
      justify-content: center;
    }

    nav a {
      padding: 4px 10px;
      border-radius: 999px;
      color: var(--dark-text);
      background-color: white;
    }

    nav a:hover {
      background-color: var(--light-gray);
    }

    section {
      padding: 32px 0;
    }

    section:nth-of-type(even) {
      background-color: var(--light-gray);
    }

    h2 {
      font-size: 1.6rem;
      margin-bottom: 12px;
      color: var(--utsa-blue);
    }

    h3 {
      font-size: 1.2rem;
      margin: 12px 0 4px;
      color: var(--utsa-blue);
    }

    p {
      margin-bottom: 10px;
      font-size: 0.98rem;
    }

    ul {
      margin-left: 1.2rem;
      margin-bottom: 10px;
      font-size: 0.96rem;
    }

    li {
      margin-bottom: 4px;
    }

    .two-column {
      display: grid;
      grid-template-columns: minmax(0, 2.1fr) minmax(0, 1.4fr);
      gap: 24px;
      align-items: flex-start;
    }

    .card {
      background-color: white;
      border-radius: 8px;
      padding: 16px 18px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.06);
    }

    .badge-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 10px;
    }

    .badge {
      font-size: 0.75rem;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      padding: 3px 8px;
      border-radius: 999px;
      border: 1px solid #ddd;
      color: var(--muted-text);
    }

    .link-buttons {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 10px;
    }

    .btn {
      display: inline-block;
      padding: 6px 14px;
      border-radius: 999px;
      font-size: 0.9rem;
      border: 1px solid var(--utsa-blue);
      color: var(--utsa-blue);
      background-color: white;
      text-decoration: none;
      white-space: nowrap;
    }

    .btn.primary {
      background-color: var(--utsa-blue);
      color: white;
      border-color: var(--utsa-blue);
    }

    .btn:hover {
      opacity: 0.9;
      text-decoration: none;
    }

    .media-placeholder {
      border-radius: 8px;
      border: 1px dashed #cccccc;
      padding: 16px;
      text-align: center;
      font-size: 0.85rem;
      color: var(--muted-text);
      background-color: #ffffff;
    }

    .media-placeholder strong {
      display: block;
      margin-bottom: 4px;
      color: var(--dark-text);
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 8px;
      font-size: 0.9rem;
    }

    th, td {
      border: 1px solid #dddddd;
      padding: 6px 8px;
      text-align: center;
    }

    th {
      background-color: #f0f3f8;
      font-weight: 600;
    }

    .qual-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 12px;
      margin-top: 10px;
    }

    .qual-item {
      background-color: white;
      border-radius: 8px;
      border: 1px solid #e0e0e0;
      padding: 10px;
      text-align: center;
      font-size: 0.85rem;
    }

    .qual-item img {
      max-width: 100%;
      border-radius: 4px;
      margin-bottom: 6px;
    }

    .videos-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
      gap: 16px;
    }

    iframe {
      width: 100%;
      aspect-ratio: 16 / 9;
      border-radius: 8px;
      border: none;
    }

    footer {
      background-color: #111111;
      color: #dddddd;
      padding: 20px 0 24px;
      font-size: 0.85rem;
      margin-top: 24px;
    }

    footer a {
      color: #e0e7ff;
    }

    @media (max-width: 800px) {
      .two-column {
        grid-template-columns: 1fr;
      }

      .hero-meta {
        text-align: left;
      }

      .hero {
        gap: 16px;
      }
    }
  </style>
</head>
<body>

  <!-- HEADER / HERO -->
  <header>
    <div class="container hero">
      <div class="hero-title">
        <h1>Evaluation and Fine-Tuning of MedSAM on the MICCAI&nbsp;FLARE22 Dataset</h1>
        <p>
          A study on adapting the Segment Anything in Medical Images (MedSAM) model to abdominal CT organ segmentation
          via dataset-specific fine-tuning and comprehensive quantitative and qualitative evaluation.
        </p>
      </div>
      <div class="hero-meta">
        <p><strong>Nasim Faridnia</strong><br>
           Department of Computer Science, University of Texas at San Antonio</p>
        <p>Advisor: Dr. Paul Rad</p>
        <span class="tag">Research Project</span>
      </div>
    </div>
  </header>

  <!-- NAVIGATION -->
  <nav>
    <div class="container">
      <ul>
        <li><a href="#abstract">Abstract</a></li>
        <li><a href="#intro">Introduction</a></li>
        <li><a href="#background">Related Work</a></li>
        <li><a href="#approach">Approach</a></li>
        <li><a href="#experiments">Experiments &amp; Results</a></li>
        <li><a href="#discussion">Discussion</a></li>
        <li><a href="#poster">Poster</a></li>
        <li><a href="#videos">Videos</a></li>
        <li><a href="#code">Code</a></li>
        <li><a href="#refs">References</a></li>
      </ul>
    </div>
  </nav>

  <!-- ABSTRACT -->
  <section id="abstract">
    <div class="container">
      <h2>Abstract</h2>
      <div class="card">
        <p>
          Medical image segmentation in abdominal CT is challenging due to low contrast, anatomical variability,
          and acquisition differences. While the Segment Anything Model (SAM) is effective on natural images,
          its performance on medical images is limited without domain adaptation.
        </p>
        <p>
          In this project, we evaluate MedSAM on the MICCAI FLARE22 abdominal CT dataset and reproduce its baseline performance.
          We then fine-tune MedSAM on FLARE22 slices using bounding box prompts derived from ground-truth masks and a modified
          training schedule with mixed-precision. Quantitative evaluation is performed using Dice and Normalized Surface Distance (NSD).
        </p>
        <p>
          Our experiments show that fine-tuning yields a modest improvement in Dice and a substantial gain in NSD,
          indicating clearer boundaries and better surface alignment. Qualitative comparisons confirm visually
          sharper contours and improved separation of neighboring organs.
        </p>
      </div>
    </div>
  </section>

  <!-- INTRODUCTION -->
  <section id="intro">
    <div class="container">
      <h2>Introduction</h2>
      <div class="two-column">
        <div>
          <h3>Problem</h3>
          <ul>
            <li>Abdominal CT organ segmentation is essential for diagnosis, treatment planning, and quantitative analysis.</li>
            <li>Manual annotations are time-consuming and require expert radiologists.</li>
            <li>Robust automated methods must cope with noise, low contrast, and high anatomical variability.</li>
          </ul>

          <h3>Research Gap</h3>
          <ul>
            <li>Traditional deep networks are often trained for a single organ or dataset and generalize poorly.</li>
            <li>General-purpose SAM underperforms on medical images without domain-specific adaptation.</li>
            <li>It remains unclear how much additional fine-tuning can improve MedSAM on a specific CT dataset such as FLARE22.</li>
          </ul>

          <h3>Motivation</h3>
          <ul>
            <li>MedSAM proposes a foundation model for medical segmentation, trained on 1.5M+ medical masks.</li>
            <li>We aim to quantify its performance on FLARE22 and assess the benefit of dataset-specific fine-tuning.</li>
          </ul>
        </div>
        <div>
          <div class="media-placeholder">
            <strong>[Optional Figure Placeholder]</strong>
            Example FLARE22 abdominal CT slice with organ mask overlay.<br>
            <em>Replace this box with an image such as <code>flare22_example.png</code>.</em>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- RELATED WORK / BACKGROUND -->
  <section id="background">
    <div class="container">
      <h2>Related Work / Background</h2>
      <div class="card">
        <div class="badge-row">
          <span class="badge">SAM</span>
          <span class="badge">MedSAM</span>
          <span class="badge">Medical Segmentation</span>
        </div>
        <ul>
          <li><strong>Segment Anything Model (SAM):</strong> Introduced promptable segmentation for a wide variety of natural images.</li>
          <li><strong>Limitations in medical imaging:</strong> Directly applying SAM to CT data leads to reduced performance due to grayscale intensity, low contrast, and domain shift.</li>
          <li><strong>MedSAM:</strong> Extends SAM by training on over 1.5M medical masks across multiple modalities, improving baseline performance in clinical settings.</li>
          <li><strong>Abdominal CT segmentation methods:</strong> Prior work (e.g., U-Net variants, nnU-Net) typically require dataset-specific training and extensive hyperparameter tuning.</li>
        </ul>
      </div>
    </div>
  </section>

  <!-- APPROACH -->
  <section id="approach">
    <div class="container">
      <h2>Approach</h2>
      <div class="two-column">
        <div>
          <h3>Preprocessing &amp; Prompt Generation</h3>
          <ul>
            <li>Convert 3D FLARE22 CT volumes to 2D PNG slices.</li>
            <li>Load corresponding organ masks and generate tight bounding boxes around each annotated organ.</li>
            <li>Use bounding boxes as prompts to MedSAM for both inference and fine-tuning.</li>
          </ul>

          <h3>Model &amp; Training</h3>
          <ul>
            <li>Start from the official MedSAM ViT-B checkpoint.</li>
            <li>Fine-tune on FLARE22 slices with a cosine learning rate schedule and mixed-precision (AMP).</li>
            <li>Use Dice-based loss and small batch sizes to fit GPU memory constraints.</li>
          </ul>

          <h3>Implementation Notes &amp; Obstacles</h3>
          <ul>
            <li>Carefully handled slices with no organ labels to avoid empty prompts.</li>
            <li>Aligned preprocessing with the original implementation for fair comparison.</li>
            <li>Balanced training time vs. performance by tuning the number of epochs and learning rate.</li>
          </ul>
        </div>
        <div>
          <div class="media-placeholder">
            <strong>[Preprocessing Flowchart Placeholder]</strong>
            Suggested flow:<br>
            <code>3D CT Volume → 2D Slice → Mask → Bounding Box → MedSAM</code><br><br>
            <em>Replace this with your flowchart image (e.g., <code>preprocessing_flowchart.png</code>).</em>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- EXPERIMENTS & RESULTS -->
  <section id="experiments">
    <div class="container">
      <h2>Experiments &amp; Results</h2>
      <div class="two-column">
        <div>
          <h3>Dataset</h3>
          <ul>
            <li>FLARE22 abdominal CT dataset with multi-organ annotations (liver, spleen, kidneys, pancreas, etc.).</li>
            <li>3D CT volumes (typically 512×512) converted to 2D slices.</li>
            <li>High anatomical variability across patients and acquisition settings.</li>
          </ul>

          <h3>Metrics</h3>
          <ul>
            <li>Dice Similarity Coefficient (DSC) to measure volumetric overlap.</li>
            <li>Normalized Surface Distance (NSD) to measure boundary and surface alignment.</li>
          </ul>

          <h3>Models Compared</h3>
          <ul>
            <li>MedSAM (as reported in the original paper).</li>
            <li>Reproduced MedSAM baseline on FLARE22.</li>
            <li>Fine-tuned MedSAM on FLARE22 (this work).</li>
          </ul>

          <h3>Quantitative Results</h3>
          <table>
            <thead>
              <tr>
                <th>Model</th>
                <th>Dice (Mean)</th>
                <th>NSD (Mean)</th>
                <th>Notes</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>MedSAM (Paper)</td>
                <td>0.7572</td>
                <td>0.4871</td>
                <td>Reported external CT validation</td>
              </tr>
              <tr>
                <td>Reproduced Default MedSAM</td>
                <td>≈ 0.75–0.76</td>
                <td>≈ 0.48–0.50</td>
                <td>Matches paper-level performance</td>
              </tr>
              <tr>
                <td><strong>Fine-Tuned MedSAM (Ours)</strong></td>
                <td><strong>0.7684</strong></td>
                <td><strong>0.5913</strong></td>
                <td>Large NSD gain, better boundaries</td>
              </tr>
            </tbody>
          </table>

          <p style="font-size:0.9rem; color:var(--muted-text); margin-top:6px;">
            Numerical values from evaluation on FLARE22 slices using the official MedSAM checkpoint and our fine-tuned model.
          </p>
        </div>

        <div>
          <div class="media-placeholder" style="margin-bottom:12px;">
            <img src="dice_plot.png" 
       alt="MedSAM Poster Preview"
       style="width:100%; border-radius:8px; margin-top:8px;">
          </div>
          <div class="media-placeholder">
           <img src="nsd_plot.png" 
       alt="MedSAM Poster Preview"
       style="width:100%; border-radius:8px; margin-top:8px;">
          </div>
          <div class="media-placeholder">
            
            
          </div>
        </div>
      </div>

      <h3 style="margin-top:24px;">Qualitative Results</h3>
      <p>
        Below are example slices comparing the ground truth, default MedSAM, and our fine-tuned MedSAM.
        The fine-tuned model shows cleaner boundaries, sharper contours, and better separation of neighboring organs.
      </p>
      <div class="qual-grid">
        <div class="qual-item">
          <!-- Replace src with your actual qualitative comparison image -->
          <img src="gt_vs_default.png" alt="Qualitative case 1"> -->
          <strong>Case 1</strong><br>
          Ground Truth vs. Default MedSAM vs. Fine-Tuned MedSAM.
        </div>
        <div class="qual-item">
          <img src="joint_mask.png" alt="Qualitative case 2"> -->
          <strong>Case 2</strong><br>
          Improved organ boundaries and reduced leakage.
        </div>
        <div class="qual-item">
          <img src="default_mask_better.png" alt="Qualitative case 3"> -->
          <strong>Case 3</strong><br>
          Better separation of adjacent organs in low-contrast regions.
        </div>
      </div>
    </div>
  </section>

  <!-- DISCUSSION, LIMITATIONS, FUTURE WORK -->
  <section id="discussion">
    <div class="container">
      <h2>Discussion, Limitations, &amp; Future Work</h2>
      <div class="card">
        <h3>Discussion</h3>
        <ul>
          <li>Fine-tuning on FLARE22 leads to a strong improvement in NSD, indicating better boundary and surface alignment.</li>
          <li>The gains are consistent across multiple qualitative examples and not limited to a single organ.</li>
          <li>This confirms that MedSAM benefits from additional dataset-specific adaptation, even with a powerful pretraining stage.</li>
        </ul>

        <h3>Limitations</h3>
        <ul>
          <li>Small organs remain challenging due to limited pixel footprint and noisy boundaries.</li>
          <li>The current pipeline operates on 2D slices and does not enforce 3D consistency.</li>
          <li>Experiments are limited to FLARE22; cross-dataset generalization is not fully explored.</li>
        </ul>

        <h3>Future Work</h3>
        <ul>
          <li>Extend experiments to multi-modal datasets (e.g., MR, ultrasound).</li>
          <li>Investigate 3D MedSAM variants and temporal consistency across slices.</li>
          <li>Explore prompt engineering strategies (e.g., multi-organ prompts, scribbles, or points) for improved segmentation control.</li>
        </ul>
      </div>
    </div>
  </section>

  <!-- POSTER -->
  <section id="poster">
    <div class="container">
      <h2>Poster</h2>
      <div class="two-column">
        <div>
          <p>
            The figure below shows the A0 research poster summarizing this project,
            including the motivation, approach, experiments, and key results.
          </p>
          <div class="link-buttons">
            <!-- Replace href with your actual poster file link (e.g., PDF hosted on GitHub or OneDrive) -->
            <a class="btn primary" href="https://github.com/NassimF/medsam-finetuning-flare22/blob/main/Poster_MedSAM_CV.pdf" target="_blank" rel="noopener">
              Download Poster (PDF)
            </a>
          </div>
          <p style="font-size:0.9rem; color:var(--muted-text); margin-top:8px;">
            
          </p>
        </div>
        <div>
          <div class="media-placeholder">
  <strong>Poster Preview</strong>
  <img src="medsam_poster_preview.png" alt="MedSAM Poster Preview" style="width:100%; border-radius:8px; margin-top:8px;">
</div>
        </div>
      </div>
    </div>
  </section>

  <!-- VIDEOS -->
  <section id="videos">
    <div class="container">
      <h2>Videos</h2>
      
      <div class="videos-grid">
        <a href="https://github.com/NassimF/medsam-finetuning-flare22/blob/main/ezyZip.mp4">Download demo video</a>
        
      </div>
    </div>
  </section>

  <!-- CODE / GITHUB -->
  <section id="code">
    <div class="container">
      <h2>Code &amp; Resources</h2>
      <div class="card">
        <p>
          The code for preprocessing, fine-tuning, and evaluation is available on GitHub.
          Please see the repository below:
        </p>
        <div class="link-buttons">
          <!-- Replace href with your actual GitHub repo -->
          <a class="btn primary" href="https://github.com/NassimF/medsam-finetuning-flare22" target="_blank" rel="noopener">
            View Code on GitHub
          </a>
          <!-- If you keep it private for grading, you can mention that here -->
        </div>
        <p style="font-size:0.9rem; color:var(--muted-text); margin-top:8px;">
         
        </p>
      </div>
    </div>
  </section>

  <!-- REFERENCES -->
  <section id="refs">
    <div class="container">
      <h2>References</h2>
      <div class="card">
        <ol style="padding-left:1.1rem; font-size:0.92rem;">
          <li>
            J. Ma, Y. He, F. Li, L. Han, C. You, and B. Wang,
            “Segment Anything in Medical Images (MedSAM),”
            <em>arXiv preprint arXiv:2304.12306</em>, 2024.
          </li>
          <li>
            A. Kirillov, E. Mintun, N. Ravi, et al.,
            “Segment Anything,”
            <em>arXiv preprint arXiv:2304.02643</em>, 2023.
          </li>
          <li>
            F. Isensee, P. F. Jaeger, S. A. A. Kohl, J. Petersen, and K. H. Maier-Hein,
            “nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation,”
            <em>Nature Methods</em>, 2021.
          </li>
        </ol>
      </div>
    </div>
  </section>

  <!-- FOOTER -->
  <footer>
    <div class="container">
      <p>
        &copy; <!-- Replace with the year if you like -->2025 Nasim Faridnia, University of Texas at San Antonio.<br>
        For questions, contact: <a href="mailto:seyedehnasim.faridnia@my.utsa.edu">seyedehnasim.faridnia@my.utsa.edu</a>.
      </p>
    </div>
  </footer>

</body>
</html>
